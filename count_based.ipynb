{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d74d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import vjp.data as data\n",
    "import vjp.preprocess as preprocess\n",
    "import vjp.folds as folds\n",
    "import vjp.text as text\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import vjp.preprocess as preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fadce0b3",
   "metadata": {},
   "source": [
    "Retrieve a preprocessed dataframe using the pipeline defined by `data_exploration.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9103a42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from file if exists (e.g. pregenerated via preprocess CLI)\n",
    "DF_FILENAME = 'connected_components.parquet'\n",
    "if os.path.exists(DF_FILENAME):\n",
    "    print(f'Reading from {DF_FILENAME}...')\n",
    "    df = pd.read_parquet(DF_FILENAME)\n",
    "else:           # Generate on the go\n",
    "    print('File not found, generating dataframe...')\n",
    "    namespace = preprocess.Namespace()\n",
    "    namespace.connected_component_tags = ('req', 'arg', 'claim', 'mot', 'dec')\n",
    "    namespace.use_child_text_tag_names = ('mot', 'dec')\n",
    "    namespace.level = preprocess.PreprocessingLevels.CONNECTED_COMPONENTS\n",
    "    df = preprocess.preprocess(namespace)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62de8e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducibility\n",
    "random_state = 1717"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ee26e5",
   "metadata": {},
   "source": [
    "## Splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492227dc",
   "metadata": {},
   "source": [
    "All tag types are gathered, so that multiple experiments may be carried out by excluding some of the columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bc841c",
   "metadata": {},
   "source": [
    "Balanced KFold splits are computed at document level using a MIP formulation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087d6a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_maps = folds.compute_decision_folds(df, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d867a6e",
   "metadata": {},
   "source": [
    "Preview of the first split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e6fc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[fold_maps[0]].shape)\n",
    "df[fold_maps[0]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b0f5f6",
   "metadata": {},
   "source": [
    "A `split` function encapsules all the kfold logic and provides train-test splits based on the its results. The function has a similar interface to the one of scikit-learn's validators, and is suitable to be used with `GridSearchCV`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83193310",
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_indeces, test_indeces in folds.split(df):\n",
    "    print(len(train_indeces), len(test_indeces))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36ed489",
   "metadata": {},
   "source": [
    "## Count based encodings\n",
    "For count based encodings (e.g. tf-idf) text data shall be cleaned in a certain way. Punctuations and symbols, most stopwords, etc. are not required, as the order and structure of sentences is generally lost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911b2a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "text.load_stopwords()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6802ea41",
   "metadata": {},
   "source": [
    "`vjp.text` contains some pipelines that: lower text, remove punctuation, remove stopwords and lemmatize. Such transformations can be applied to the desired features before feeding them to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7decd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = ['fact', 'req', 'arg', 'claim', 'mot', 'dec']\n",
    "\n",
    "df[tags] = df[tags].applymap(text.count_drop_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbe070e",
   "metadata": {},
   "source": [
    "Features are concatenated for easier vectorization and labels are splitted as demanded by `sklearn` models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b8aedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data.count_based_X_y(df, ['fact', 'req', 'arg', 'claim'])\n",
    "print(X.head())\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebde989",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d64081",
   "metadata": {},
   "source": [
    "A simple dummy baseline is defined (defaults to majority class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f760b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_baseline = DummyClassifier(random_state=random_state)\n",
    "avg_results = cross_val_score(dummy_baseline, X, y, cv=folds.split(df),\n",
    "                              scoring='f1_macro', n_jobs=-1).mean()\n",
    "\n",
    "print('Prior dummy, F1 macro avg:', avg_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445c4d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = Pipeline([('vectorizer', TfidfVectorizer()),\n",
    "                          ('model', RandomForestClassifier(\n",
    "                              random_state=random_state))])\n",
    "avg_results = cross_val_score(random_forest, X, y, cv=folds.split(df),\n",
    "                              scoring='f1_macro', n_jobs=-1).mean()\n",
    "\n",
    "print('Random forest, F1 macro avg:', avg_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VJP",
   "language": "python",
   "name": "vjp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "44c8d51243964ac018940b6314270b9dce7e7671e647e320692ad953ee52b48e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
