{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d74d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import vjp.preprocess as preprocess\n",
    "import vjp.lemmatization as lemmatization\n",
    "\n",
    "import string\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "import nltk\n",
    "from nltk.corpus import stopwords, words\n",
    "from nltk.corpus import wordnet as wn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import vjp.preprocess as preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fadce0b3",
   "metadata": {},
   "source": [
    "Retrieve a preprocessed dataframe using the pipeline defined by `data_exploration.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9103a42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from file if exists (e.g. pregenerated via preprocess CLI)\n",
    "DF_FILENAME = 'connected_components.parquet'\n",
    "if os.path.exists(DF_FILENAME):\n",
    "    print(f'Reading from {DF_FILENAME}...')\n",
    "    df = pd.read_parquet(DF_FILENAME)\n",
    "else:           # Generate on the go\n",
    "    print('File not found, generating dataframe...')\n",
    "    namespace = preprocess.Namespace()\n",
    "    namespace.connected_component_tags = ('req', 'arg', 'claim', 'mot', 'dec')\n",
    "    namespace.use_child_text_tag_names = ('mot', 'dec')\n",
    "    namespace.level = preprocess.PreprocessingLevels.CONNECTED_COMPONENTS\n",
    "    df = preprocess.preprocess(namespace)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492227dc",
   "metadata": {},
   "source": [
    "All tag types are gathered, so that multiple experiments may be carried out by excluding some of the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f5c6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" def remove_punctuations(text):\n",
    "  for char_to_remove in string.punctuation:\n",
    "      text = text.replace(char_to_remove, '')\n",
    "  return text \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e218ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" def remove_punctuations(text):\n",
    "  text_without_punctuation = []\n",
    "  for char_to_remove in text:\n",
    "      if  not(char_to_remove.isalnum() or char_to_remove.isspace()):\n",
    "        char_to_remove = \" \"\n",
    "      text_without_punctuation.append(char_to_remove)\n",
    "  return \"\".join(text_without_punctuation) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85422e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('punkt') \n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72238c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "cane_lemma = wn.lemmas(\"andare\",lang=\"ita\")\n",
    "print(cane_lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ad02f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(cane_lemma[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dddc926",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dir(cane_lemma[0]))\n",
    "print(cane_lemma[0].name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58448130",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuations(text):\n",
    "    return \"\".join([c if c.isalnum() else \" \" for c in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f374859f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stopwords(file):\n",
    "    stopwords = []\n",
    "    with open(file,'r',encoding='utf-8') as data_file:\n",
    "        for line in data_file:\n",
    "            stopwords.append(line.splitlines())\n",
    "    return stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf8dbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_remove_stopwords(text):\n",
    "    italian_stopwords = stopwords.words('italian')\n",
    "    text = remove_stopwords(text,stopwords=italian_stopwords) \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e539484",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7decd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = ['fact','req', 'arg', 'claim', 'mot', 'dec']\n",
    "file_name = \"italian.txt\"\n",
    "italian_stopwords = stopwords.words('italian')\n",
    "\n",
    "for column_name in tags:\n",
    "    df[column_name] = df[column_name].str.lower()\n",
    "    df[column_name] = df[column_name].apply(remove_punctuations)\n",
    "    df[column_name] = df[column_name].apply(my_remove_stopwords)\n",
    "    \n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0154c07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unified = df[\"req\"]+df[\"arg\"]+df[\"claim\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f760b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "result = vectorizer.fit_transform(df_unified)\n",
    "print(vectorizer.get_feature_names_out())\n",
    "print(len(vectorizer.get_feature_names_out()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f675ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas = lemmatization.load_lemmas()\n",
    "print(type(lemmas))\n",
    "print(list(lemmas.keys())[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3aa76ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(lemmas.items())\n",
    "len(set(lemmas.values()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VJP",
   "language": "python",
   "name": "vjp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "44c8d51243964ac018940b6314270b9dce7e7671e647e320692ad953ee52b48e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
